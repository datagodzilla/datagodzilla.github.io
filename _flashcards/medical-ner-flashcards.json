{
  "title": "Medical NER Pipeline Flashcards",
  "description": "Study cards for the Enhanced Medical NER Pipeline",
  "version": "1.0.0",
  "created": "2025-01-04",
  "total_cards": 30,
  "cards": [
    {"id": 1, "front": "What is NER? What does it stand for?", "back": "NER stands for Named Entity Recognition. It identifies and classifies named entities (diseases, medications, genes) in unstructured text into predefined categories.", "tags": ["nlp", "entity-detection", "core-concepts"]},
    {"id": 2, "front": "What is BioBERT? Why use it for medical text?", "back": "BioBERT is a domain-specific language model pre-trained on biomedical literature (PubMed). It outperforms general BERT on medical NER because it understands medical terminology and context.", "tags": ["biobert", "nlp", "core-concepts"]},
    {"id": 3, "front": "What is the hybrid approach in the Medical NER Pipeline?", "back": "The hybrid approach combines: (1) BioBERT transformer models for deep learning-based entity recognition, (2) Template-based matching with 57,476 curated medical terms, (3) Scope reversal detection for context understanding.", "tags": ["architecture", "core-concepts"]},
    {"id": 4, "front": "What are the 3 BioBERT models used in the pipeline?", "back": "1. BioBERT-Disease for disease/condition detection, 2. BioBERT-Chemical for medication and drug recognition, 3. BioBERT-Gene for gene/protein detection.", "tags": ["biobert", "entity-detection"]},
    {"id": 5, "front": "What is template-based boosting?", "back": "Template-based boosting enhances entity detection by matching text against 57,476 curated medical terms. It catches entities BioBERT might miss and improves recall.", "tags": ["templates", "entity-detection"]},
    {"id": 6, "front": "How many curated medical terms are in the template?", "back": "57,476 curated terms: 42,000+ diseases, 5,242 chemicals/drugs, and 10,234 genes/proteins.", "tags": ["templates", "core-concepts"]},
    {"id": 7, "front": "What is scope reversal detection?", "back": "Scope reversal detection identifies when linguistic markers (but, however, yet) change the context mid-sentence. Example: 'denies fever but has cough' - fever is negated, cough is confirmed.", "tags": ["scope-reversal", "context-classification"]},
    {"id": 8, "front": "What are the 5 context types in the pipeline?", "back": "1. CONFIRMED - active condition, 2. NEGATED - explicitly denied, 3. UNCERTAIN - possible/suspected, 4. HISTORICAL - past condition, 5. FAMILY - family history.", "tags": ["context-classification", "core-concepts"]},
    {"id": 9, "front": "What is the entity detection accuracy of the pipeline?", "back": "96% entity detection accuracy, combining BioBERT precision with template-based recall boost.", "tags": ["entity-detection", "performance"]},
    {"id": 10, "front": "What is the context classification accuracy?", "back": "93% context classification accuracy with scope reversal detection enabled.", "tags": ["context-classification", "performance"]},
    {"id": 11, "front": "What are the 5 stages of the pipeline?", "back": "Stage 1: Base NLP (spaCy), Stage 2: Entity Extraction (BioBERT + Templates), Stage 3: Context Classification, Stage 4: Section Detection, Stage 5: Output Generation.", "tags": ["architecture", "pipeline-stages"]},
    {"id": 12, "front": "What does Stage 1 (Base NLP) do?", "back": "Performs foundational text processing: tokenization, sentence segmentation, POS tagging, and dependency parsing using spaCy.", "tags": ["architecture", "nlp"]},
    {"id": 13, "front": "What does Stage 2 (Entity Extraction) do?", "back": "Extracts medical entities through BioBERT inference on 3 models, template matching against 57,476 terms, word boundary validation, and confidence scoring.", "tags": ["architecture", "entity-detection"]},
    {"id": 14, "front": "What does Stage 3 (Context Classification) do?", "back": "Classifies entity context using 446 total patterns (138 confirmed, 99 negated, 48 uncertain, 82 historical, 79 family) plus 103 scope reversal patterns.", "tags": ["architecture", "context-classification"]},
    {"id": 15, "front": "How many negation patterns are used in the pipeline?", "back": "99 negation patterns including: denies, no evidence of, negative for, ruled out, without, absent, free of.", "tags": ["context-classification", "patterns"]},
    {"id": 16, "front": "How many confirmation patterns are used?", "back": "138 confirmation patterns including: diagnosed with, has, presents with, positive for, confirmed.", "tags": ["context-classification", "patterns"]},
    {"id": 17, "front": "What is the context priority hierarchy?", "back": "Priority from highest to lowest: 1. NEGATED (overrides all), 2. FAMILY, 3. HISTORICAL, 4. UNCERTAIN, 5. CONFIRMED (default).", "tags": ["context-classification", "architecture"]},
    {"id": 18, "front": "What is word boundary validation?", "back": "Ensures template matches are complete words, not substrings. 'fever' matches 'has fever' but not 'fevered'. Uses regex boundaries to prevent false positives.", "tags": ["entity-detection", "templates"]},
    {"id": 19, "front": "What is template-priority mode?", "back": "Mode where template matches (confidence 0.95) take precedence over BioBERT detections (0.85). Useful for curated domain-specific terminology.", "tags": ["templates", "architecture"]},
    {"id": 20, "front": "How is confidence scoring calculated?", "back": "Total Score = Strength Points (max 40) + Proximity Points (max 40) + Structure Points (max 20). Pattern specificity and distance from entity determine final score.", "tags": ["architecture", "confidence-scoring"]},
    {"id": 21, "front": "What NLP library is the foundation of the pipeline?", "back": "spaCy is the foundational NLP library, using en_core_web_sm model for tokenization, POS tagging, and dependency parsing.", "tags": ["nlp", "libraries"]},
    {"id": 22, "front": "What is scispaCy?", "back": "scispaCy is a spaCy extension with models trained on biomedical and scientific literature, providing better tokenization and vocabulary for medical text.", "tags": ["nlp", "libraries"]},
    {"id": 23, "front": "What is negspacy?", "back": "negspacy is a spaCy component for negation detection based on the NegEx algorithm, providing baseline pattern matching for clinical negation.", "tags": ["context-classification", "libraries"]},
    {"id": 24, "front": "How many columns are in the Excel output?", "back": "43 columns including: entity text, entity type, context, confidence score, source, section, predictors, and context sentences.", "tags": ["output-format"]},
    {"id": 25, "front": "What visualization format is used?", "back": "HTML visualization with color-coded entity highlighting (Disease=red, Drug=blue) and context icons (‚ùå Negated, üìÖ Historical, üë®‚Äçüë©‚Äçüëß Family).", "tags": ["visualization"]},
    {"id": 26, "front": "What is the processing speed of the pipeline?", "back": "Approximately 0.9 rows per second, processing 5 documents in about 5 seconds with all 3 BioBERT models loaded.", "tags": ["performance"]},
    {"id": 27, "front": "What web framework powers the UI?", "back": "Streamlit powers the interactive web interface, providing text input, file upload, real-time processing, and export options.", "tags": ["ui", "streamlit"]},
    {"id": 28, "front": "What are reversal triggers in scope reversal detection?", "back": "Words that change context mid-sentence: but, however, yet, although, except, apart from. Example: 'denies X but reports Y'.", "tags": ["scope-reversal", "patterns"]},
    {"id": 29, "front": "How many scope reversal patterns exist in the system?", "back": "103 scope reversal patterns covering adversative conjunctions and their contextual variations.", "tags": ["scope-reversal"]},
    {"id": 30, "front": "What are the template file sources?", "back": "Templates sourced from: ICD-10 codes, SNOMED CT, RxNorm (drugs), LOINC (labs), and curated medical terminology databases.", "tags": ["templates", "configuration"]}
  ]
}
