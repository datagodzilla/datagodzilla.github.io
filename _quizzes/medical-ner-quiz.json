{
  "title": "Medical NER Pipeline Quiz",
  "description": "Test your knowledge of the Enhanced Medical NER Pipeline",
  "version": "1.0.0",
  "total_questions": 25,
  "questions": [
    {"id": 1, "type": "multiple_choice", "question": "How many BioBERT models are used in the Enhanced Medical NER Pipeline?", "options": ["1", "2", "3", "4"], "correct_answer": "3", "explanation": "The pipeline uses 3 BioBERT models: Disease, Chemical, and Gene detection models.", "difficulty": "easy", "tags": ["architecture", "biobert"]},
    {"id": 2, "type": "multiple_choice", "question": "What is the hybrid approach combining?", "options": ["Rule-based only", "BioBERT + Templates", "Statistical models only", "Dictionary lookup only"], "correct_answer": "BioBERT + Templates", "explanation": "The hybrid approach combines BioBERT deep learning with 57,476 curated medical term templates.", "difficulty": "easy", "tags": ["architecture"]},
    {"id": 3, "type": "multiple_choice", "question": "How many stages are in the pipeline?", "options": ["3", "4", "5", "6"], "correct_answer": "5", "explanation": "5 stages: Base NLP, Entity Extraction, Context Classification, Section Detection, Output Generation.", "difficulty": "easy", "tags": ["architecture"]},
    {"id": 4, "type": "multiple_choice", "question": "What does template-priority mode do?", "options": ["Disables BioBERT", "Gives templates higher confidence than BioBERT", "Only uses templates", "Randomizes priority"], "correct_answer": "Gives templates higher confidence than BioBERT", "explanation": "Template matches get 0.95 confidence vs BioBERT's 0.85, prioritizing expert-curated patterns.", "difficulty": "medium", "tags": ["templates"]},
    {"id": 5, "type": "multiple_choice", "question": "Which stage handles context classification?", "options": ["Stage 1", "Stage 2", "Stage 3", "Stage 4"], "correct_answer": "Stage 3", "explanation": "Stage 3 classifies context (confirmed, negated, uncertain, historical, family).", "difficulty": "easy", "tags": ["architecture"]},
    {"id": 6, "type": "multiple_choice", "question": "What is the default confidence threshold for negation?", "options": ["50%", "70%", "80%", "90%"], "correct_answer": "80%", "explanation": "Negation uses 80% threshold - strict to avoid false positives.", "difficulty": "medium", "tags": ["context-classification"]},
    {"id": 7, "type": "multiple_choice", "question": "What library provides base NLP functionality?", "options": ["NLTK", "spaCy", "Stanford NLP", "Gensim"], "correct_answer": "spaCy", "explanation": "spaCy with en_core_web_sm provides tokenization, POS tagging, and dependency parsing.", "difficulty": "easy", "tags": ["architecture", "libraries"]},
    {"id": 8, "type": "multiple_choice", "question": "How many context types exist?", "options": ["3", "4", "5", "6"], "correct_answer": "5", "explanation": "5 types: Confirmed, Negated, Uncertain, Historical, Family.", "difficulty": "easy", "tags": ["context-classification"]},
    {"id": 9, "type": "multiple_choice", "question": "How many curated medical terms are in the templates?", "options": ["10,000", "25,000", "57,476", "100,000"], "correct_answer": "57,476", "explanation": "57,476 terms: 42K+ diseases, 5.2K chemicals, 10.2K genes.", "difficulty": "medium", "tags": ["templates"]},
    {"id": 10, "type": "multiple_choice", "question": "What are the 3 entity types detected?", "options": ["Symptom/Drug/Gene", "Disease/Chemical/Gene", "Person/Org/Location", "Problem/Test/Treatment"], "correct_answer": "Disease/Chemical/Gene", "explanation": "BioBERT models detect Disease, Chemical/Drug, and Gene/Protein entities.", "difficulty": "easy", "tags": ["entity-detection"]},
    {"id": 11, "type": "multiple_choice", "question": "What is the entity detection accuracy?", "options": ["85%", "90%", "96%", "99%"], "correct_answer": "96%", "explanation": "96% entity detection accuracy from hybrid BioBERT + template approach.", "difficulty": "easy", "tags": ["performance"]},
    {"id": 12, "type": "multiple_choice", "question": "What confidence is assigned to template matches?", "options": ["0.75", "0.85", "0.95", "1.00"], "correct_answer": "0.95", "explanation": "Template exact matches get 0.95 confidence due to high precision of curated terms.", "difficulty": "medium", "tags": ["templates"]},
    {"id": 13, "type": "multiple_choice", "question": "What validates entity boundaries?", "options": ["Character count", "Word boundary regex", "ML model", "Dictionary lookup"], "correct_answer": "Word boundary regex", "explanation": "Regex word boundaries (\\b) prevent substring matches like 'pain' in 'spain'.", "difficulty": "hard", "tags": ["entity-detection"]},
    {"id": 14, "type": "multiple_choice", "question": "What suppresses false positives?", "options": ["Minimum confidence threshold", "Entity deduplication", "Manual review", "Random sampling"], "correct_answer": "Entity deduplication", "explanation": "Deduplication removes overlapping entities, keeping longer/more specific ones.", "difficulty": "medium", "tags": ["entity-detection"]},
    {"id": 15, "type": "true_false", "question": "BioBERT detections always override template matches.", "options": ["True", "False"], "correct_answer": "False", "explanation": "FALSE. In template-priority mode, templates (0.95) override BioBERT (0.85).", "difficulty": "easy", "tags": ["entity-detection"]},
    {"id": 16, "type": "multiple_choice", "question": "Which context type has highest priority?", "options": ["Confirmed", "Negated", "Historical", "Family"], "correct_answer": "Negated", "explanation": "Negated has highest priority - most clinically significant.", "difficulty": "medium", "tags": ["context-classification"]},
    {"id": 17, "type": "multiple_choice", "question": "How many negation patterns are used?", "options": ["50", "75", "99", "150"], "correct_answer": "99", "explanation": "99 negation patterns: denies, no evidence of, negative for, ruled out, etc.", "difficulty": "medium", "tags": ["patterns"]},
    {"id": 18, "type": "multiple_choice", "question": "What is the context classification accuracy?", "options": ["85%", "89%", "93%", "97%"], "correct_answer": "93%", "explanation": "93% accuracy with scope reversal detection enabled.", "difficulty": "easy", "tags": ["performance"]},
    {"id": 19, "type": "fill_in_blank", "question": "_____ patterns detect scope reversals that change assertion status.", "options": ["103", "50", "200", "75"], "correct_answer": "103", "explanation": "103 scope reversal patterns handle adversative conjunctions like 'but', 'however'.", "difficulty": "hard", "tags": ["scope-reversal"]},
    {"id": 20, "type": "true_false", "question": "Entities can belong to multiple context types simultaneously.", "options": ["True", "False"], "correct_answer": "False", "explanation": "FALSE. Each entity belongs to exactly ONE context type based on priority hierarchy.", "difficulty": "medium", "tags": ["context-classification"]},
    {"id": 21, "type": "multiple_choice", "question": "What is scope reversal?", "options": ["BioBERT prediction change", "Context changes mid-sentence", "Template override", "Error correction"], "correct_answer": "Context changes mid-sentence", "explanation": "Scope reversal: 'denies X but reports Y' - X negated, Y affirmed.", "difficulty": "medium", "tags": ["scope-reversal"]},
    {"id": 22, "type": "multiple_choice", "question": "Name THREE reversal triggers:", "options": ["and, or, if", "but, however, although", "with, without, except", "when, while, since"], "correct_answer": "but, however, although", "explanation": "Adversative conjunctions: but, however, although, yet, except.", "difficulty": "easy", "tags": ["scope-reversal"]},
    {"id": 23, "type": "multiple_choice", "question": "How many reversal patterns exist?", "options": ["50", "75", "103", "150"], "correct_answer": "103", "explanation": "103 patterns covering various adversative conjunctions.", "difficulty": "hard", "tags": ["scope-reversal"]},
    {"id": 24, "type": "fill_in_blank", "question": "'denies fever _____ has cough' - what word triggers reversal?", "options": ["but", "and", "with", "or"], "correct_answer": "but", "explanation": "'but' is an adversative conjunction that reverses the negation scope.", "difficulty": "easy", "tags": ["scope-reversal"]},
    {"id": 25, "type": "true_false", "question": "'but' is recognized as a scope reversal trigger.", "options": ["True", "False"], "correct_answer": "True", "explanation": "TRUE. 'but' is a primary reversal trigger signaling context change.", "difficulty": "easy", "tags": ["scope-reversal"]}
  ]
}
